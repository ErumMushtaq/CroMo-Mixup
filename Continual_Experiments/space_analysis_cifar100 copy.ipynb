{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"\")))\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "\n",
    "from dataloaders.dataloader_cifar10 import get_cifar10\n",
    "from dataloaders.dataloader_cifar100 import get_cifar100\n",
    "from utils.eval_metrics import linear_evaluation, get_t_SNE_plot\n",
    "from models.linear_classifer import LinearClassifier\n",
    "from models.ssl import  SimSiam, Siamese, Encoder, Predictor\n",
    "\n",
    "from trainers.train_simsiam import train_simsiam\n",
    "from trainers.train_infomax import train_infomax\n",
    "from trainers.train_barlow import train_barlow\n",
    "\n",
    "from trainers.train_PFR import train_PFR_simsiam\n",
    "from trainers.train_PFR_contrastive import train_PFR_contrastive_simsiam\n",
    "from trainers.train_contrastive import train_contrastive_simsiam\n",
    "from trainers.train_ering import train_ering_simsiam\n",
    "\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from utils.lr_schedulers import LinearWarmupCosineAnnealingLR, SimSiamScheduler\n",
    "from utils.eval_metrics import Knn_Validation_cont\n",
    "from copy import deepcopy\n",
    "from loss import invariance_loss,CovarianceLoss,ErrorCovarianceLoss\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[0.1, 2.0]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = torchvision.transforms.functional.gaussian_blur(x,kernel_size=[3,3],sigma=sigma)#kernel size and sigma are open problems but right now seems ok!\n",
    "        return x\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    normalization = 'group'\n",
    "    weight_standard = False\n",
    "    same_lr = False\n",
    "    pretrain_batch_size = 512\n",
    "    pretrain_warmup_epochs = 10\n",
    "    pretrain_warmup_lr = 3e-3\n",
    "    pretrain_base_lr = 0.03\n",
    "    pretrain_momentum = 0.9\n",
    "    pretrain_weight_decay = 5e-4\n",
    "    min_lr = 0.00\n",
    "    lambdap = 1.0\n",
    "    appr = 'barlow_PFR'\n",
    "    knn_report_freq = 10\n",
    "    cuda_device = 5\n",
    "    num_workers = 8\n",
    "    contrastive_ratio = 0.001\n",
    "    dataset = 'cifar100'\n",
    "    class_split = [25,25,25,25]\n",
    "    epochs = [500,500,500,500]\n",
    "    cov_loss_weight = 1.0\n",
    "    sim_loss_weight = 250.0\n",
    "    info_loss = 'invariance'\n",
    "    lambda_norm = 1.0\n",
    "    subspace_rate = 0.99\n",
    "    lambda_param = 5e-3\n",
    "    bsize = 32\n",
    "    msize = 150\n",
    "    proj_hidden = 2048\n",
    "    proj_out = 2048 #infomax 64\n",
    "    pred_hidden = 512\n",
    "    pred_out = 2048\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"cifar10\":\n",
    "    get_dataloaders = get_cifar10\n",
    "    num_classes=10\n",
    "elif args.dataset == \"cifar100\":\n",
    "    get_dataloaders = get_cifar100\n",
    "    num_classes=100\n",
    "assert sum(args.class_split) == num_classes\n",
    "assert len(args.class_split) == len(args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "num_worker = args.num_workers\n",
    "#device\n",
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb init\n",
    "wandb.init(project=\"CSSL\",  entity=\"yavuz-team\",\n",
    "            mode=\"disabled\",\n",
    "            config=args,\n",
    "            name= str(args.dataset) + '-algo' + str(args.appr) + \"-e\" + str(args.epochs) + \"-b\" \n",
    "            + str(args.pretrain_batch_size) + \"-lr\" + str(args.pretrain_base_lr)+\"-CS\"+str(args.class_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    transform = T.Compose([\n",
    "            T.RandomResizedCrop(size=32, scale=(0.2, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)]), p=0.8),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomApply([GaussianBlur()], p=0.5), \n",
    "            T.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "    transform_prime = T.Compose([\n",
    "            T.RandomResizedCrop(size=32, scale=(0.2, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)]), p=0.8),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomApply([GaussianBlur()], p=0.5), \n",
    "            T.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataloaders..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Dataloaders\n",
    "print(\"Creating Dataloaders..\")\n",
    "#Class Based\n",
    "train_data_loaders, train_data_loaders_knn, test_data_loaders, _, train_data_loaders_linear, train_data_loaders_pure  = get_dataloaders(transform, transform_prime, \\\n",
    "                                    classes=args.class_split, valid_rate = 0.00, batch_size=args.pretrain_batch_size, seed = 0, num_worker= num_worker)\n",
    "_, train_data_loaders_knn_all, test_data_loaders_all, _, train_data_loaders_linear_all, train_data_loaders_pure_all = get_dataloaders(transform, transform_prime, \\\n",
    "                                        classes=[num_classes], valid_rate = 0.00, batch_size=args.pretrain_batch_size, seed = 0, num_worker= num_worker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    proj_hidden = args.proj_hidden\n",
    "    proj_out = args.proj_out\n",
    "    encoder = Encoder(hidden_dim=proj_hidden, output_dim=proj_out, normalization = args.normalization, weight_standard = args.weight_standard,appr_name =args.appr)\n",
    "    model = Siamese(encoder)\n",
    "    model.to(device) #automatically detects from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model here\n",
    "file_name = 'checkpoints/checkpoint_cifar100-algocassle_barlow-e[500, 500, 500, 500]-b256-lr0.06-CS[25, 25, 25, 25]acc_62.57.pth.tar'\n",
    "dict = torch.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.temporal_projector = nn.Sequential(\n",
    "            nn.Linear(args.proj_out, args.proj_hidden, bias=False),\n",
    "            nn.BatchNorm1d(args.proj_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.proj_hidden, args.proj_out),\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_performance(model, loaders, test_loaders):\n",
    "    X = []\n",
    "    y = []\n",
    "    Xtest = []\n",
    "    ytest = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for task, loader in enumerate(loaders):\n",
    "            for data_tuple in loader:\n",
    "                data, target = [t.to(device) for t in data_tuple]\n",
    "                output = model(data)\n",
    "                X.append(output.cpu().numpy())\n",
    "                y.append(target.cpu().numpy())\n",
    "        for task, loader in enumerate(test_loaders):\n",
    "            for data_tuple in loader:\n",
    "                data, target = [t.to(device) for t in data_tuple]\n",
    "                output = model(data)\n",
    "                Xtest.append(output.cpu().numpy())\n",
    "                ytest.append(target.cpu().numpy())\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "    Xtest = np.concatenate(Xtest)\n",
    "    ytest = np.concatenate(ytest)\n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    clf.fit(X, y)\n",
    "    return clf.score(X, y), clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Performance of the model train: 0.73062  test: 0.5405\n"
     ]
    }
   ],
   "source": [
    "total_acc_train,  total_acc_test = total_performance(model, train_data_loaders_knn, test_data_loaders)#Not real performance just shows the linear seperability\n",
    "print(f'Total Performance of the model train: {total_acc_train}  test: {total_acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clf(model, loader, test_loader):\n",
    "    X = []\n",
    "    y = []\n",
    "    Xtest = []\n",
    "    ytest = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data_tuple in loader:\n",
    "            data, target = [t.to(device) for t in data_tuple]\n",
    "            # Forward prop of the model with single augmented batch\n",
    "            output = model(data)\n",
    "            X.append(output.cpu().numpy())\n",
    "            y.append(target.cpu().numpy())\n",
    "        for data_tuple in test_loader:\n",
    "            data, target = [t.to(device) for t in data_tuple]\n",
    "            # Forward prop of the model with single augmented batch\n",
    "            output = model(data)\n",
    "            Xtest.append(output.cpu().numpy())\n",
    "            ytest.append(target.cpu().numpy())\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "    Xtest = np.concatenate(Xtest)\n",
    "    ytest = np.concatenate(ytest)\n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    clf.fit(X, y)\n",
    "    return clf.score(X, y), clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0  acc train: 89.480000   acc test: 71.680000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1  acc train: 86.912000   acc test: 67.440000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2  acc train: 90.424000   acc test: 68.640000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3  acc train: 95.248000   acc test: 74.280000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "for task, loader in enumerate(train_data_loaders_knn):\n",
    "    acc, acc_test = train_clf(model, loader, test_data_loaders[task])\n",
    "    print(f\"Task {task}  acc train: {acc*100:2f}   acc test: {acc_test*100:2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_task_seperation(model, loaders, test_loaders):\n",
    "    X = []\n",
    "    y = []\n",
    "    Xtest = []\n",
    "    ytest = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for task, loader in enumerate(loaders):\n",
    "            for (data, target) in loader:\n",
    "                output = model(data.to(device))\n",
    "                X.append(output.cpu().numpy())\n",
    "                for k in range(len(target)):\n",
    "                    y.append(task)\n",
    "        for task, loader in enumerate(test_loaders):\n",
    "            for (data, target) in loader:\n",
    "                output = model(data.to(device))\n",
    "                Xtest.append(output.cpu().numpy())\n",
    "                for k in range(len(target)):\n",
    "                    ytest.append(task)\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    y = np.array(y)\n",
    "    Xtest = np.concatenate(Xtest)\n",
    "    ytest = np.array(ytest)\n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    clf.fit(X, y)\n",
    "    return clf.score(X, y), clf.score(Xtest, ytest)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task linear seperable performance train: 0.50926  test: 0.4943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "task_seperability, task_seperability_test = train_task_seperation(model, train_data_loaders_knn, test_data_loaders)\n",
    "print(f'Task linear seperable performance train: {task_seperability}  test: {task_seperability_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model here\n",
    "file_name = 'checkpoints/checkpoint_cifar100-algoLRD_barlow-e[500, 500, 500, 500]-b256-lr0.06-CS[25, 25, 25, 25]_task_0_lambdap_10.0_lambda_norm_0.1_same_lr_False_norm_batch_ws_False.pth.tar'\n",
    "dict = torch.load(file_name)\n",
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    proj_hidden = args.proj_hidden\n",
    "    proj_out = args.proj_out\n",
    "    encoder = Encoder(hidden_dim=proj_hidden, output_dim=proj_out, normalization = 'batch', weight_standard = args.weight_standard,appr_name =args.appr)\n",
    "    old_model = Siamese(encoder)\n",
    "    old_model.to(device) #automatically detects from model\n",
    "\n",
    "old_model.load_state_dict(dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Performance of the model train: 0.69098  test: 0.4925\n"
     ]
    }
   ],
   "source": [
    "total_acc_train,  total_acc_test = total_performance(old_model, train_data_loaders_knn, test_data_loaders)#Not real performance just shows the linear seperability\n",
    "print(f'Total Performance of the model train: {total_acc_train}  test: {total_acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0  acc train: 92.136000   acc test: 69.360000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1  acc train: 84.672000   acc test: 60.920000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2  acc train: 86.136000   acc test: 63.920000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3  acc train: 90.000000   acc test: 68.080000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "for task, loader in enumerate(train_data_loaders_knn):\n",
    "    acc, acc_test = train_clf(old_model, loader, test_data_loaders[task])\n",
    "    print(f\"Task {task}  acc train: {acc*100:2f}   acc test: {acc_test*100:2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task linear seperable performance train: 0.52462  test: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "task_seperability, task_seperability_test = train_task_seperation(old_model, train_data_loaders_knn, test_data_loaders)\n",
    "print(f'Task linear seperable performance train: {task_seperability}  test: {task_seperability_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model here\n",
    "file_name = 'checkpoints/checkpoint_cifar100-algoLRD_barlow-e[500, 500, 500, 500]-b256-lr0.06-CS[25, 25, 25, 25]_task_1_lambdap_10.0_lambda_norm_0.1_same_lr_False_norm_batch_ws_False.pth.tar'\n",
    "dict = torch.load(file_name)\n",
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    proj_hidden = args.proj_hidden\n",
    "    proj_out = args.proj_out\n",
    "    encoder = Encoder(hidden_dim=proj_hidden, output_dim=proj_out, normalization = 'batch', weight_standard = args.weight_standard,appr_name =args.appr)\n",
    "    old_model = Siamese(encoder)\n",
    "    old_model.to(device) #automatically detects from model\n",
    "\n",
    "old_model.load_state_dict(dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Performance of the model train: 0.71624  test: 0.5069\n",
      "Task 0  acc train: 92.152000   acc test: 68.960000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1  acc train: 89.544000   acc test: 66.800000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2  acc train: 87.032000   acc test: 63.240000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3  acc train: 91.088000   acc test: 67.480000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task linear seperable performance train: 0.52936  test: 0.5116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "total_acc_train,  total_acc_test = total_performance(old_model, train_data_loaders_knn, test_data_loaders)#Not real performance just shows the linear seperability\n",
    "print(f'Total Performance of the model train: {total_acc_train}  test: {total_acc_test}')\n",
    "for task, loader in enumerate(train_data_loaders_knn):\n",
    "    acc, acc_test = train_clf(old_model, loader, test_data_loaders[task])\n",
    "    print(f\"Task {task}  acc train: {acc*100:2f}   acc test: {acc_test*100:2f}\")\n",
    "    print()\n",
    "\n",
    "task_seperability, task_seperability_test = train_task_seperation(old_model, train_data_loaders_knn, test_data_loaders)\n",
    "print(f'Task linear seperable performance train: {task_seperability}  test: {task_seperability_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model here\n",
    "file_name = 'checkpoints/checkpoint_cifar100-algoLRD_barlow-e[500, 500, 500, 500]-b256-lr0.06-CS[25, 25, 25, 25]_task_2_lambdap_10.0_lambda_norm_0.1_same_lr_False_norm_batch_ws_False.pth.tar'\n",
    "dict = torch.load(file_name)\n",
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    proj_hidden = args.proj_hidden\n",
    "    proj_out = args.proj_out\n",
    "    encoder = Encoder(hidden_dim=proj_hidden, output_dim=proj_out, normalization = 'batch', weight_standard = args.weight_standard,appr_name =args.appr)\n",
    "    old_model = Siamese(encoder)\n",
    "    old_model.to(device) #automatically detects from model\n",
    "\n",
    "old_model.load_state_dict(dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Performance of the model train: 0.72046  test: 0.5151\n",
      "Task 0  acc train: 91.120000   acc test: 68.040000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1  acc train: 88.352000   acc test: 66.000000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2  acc train: 90.384000   acc test: 66.280000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3  acc train: 91.080000   acc test: 70.040000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task linear seperable performance train: 0.534  test: 0.5117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "total_acc_train,  total_acc_test = total_performance(old_model, train_data_loaders_knn, test_data_loaders)#Not real performance just shows the linear seperability\n",
    "print(f'Total Performance of the model train: {total_acc_train}  test: {total_acc_test}')\n",
    "for task, loader in enumerate(train_data_loaders_knn):\n",
    "    acc, acc_test = train_clf(old_model, loader, test_data_loaders[task])\n",
    "    print(f\"Task {task}  acc train: {acc*100:2f}   acc test: {acc_test*100:2f}\")\n",
    "    print()\n",
    "\n",
    "task_seperability, task_seperability_test = train_task_seperation(old_model, train_data_loaders_knn, test_data_loaders)\n",
    "print(f'Task linear seperable performance train: {task_seperability}  test: {task_seperability_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model here\n",
    "file_name = 'checkpoints/checkpoint_cifar100-algoLRD_barlow-e[500, 500, 500, 500]-b256-lr0.06-CS[25, 25, 25, 25]_task_3_lambdap_10.0_lambda_norm_0.1_same_lr_False_norm_batch_ws_False.pth.tar'\n",
    "dict = torch.load(file_name)\n",
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    proj_hidden = args.proj_hidden\n",
    "    proj_out = args.proj_out\n",
    "    encoder = Encoder(hidden_dim=proj_hidden, output_dim=proj_out, normalization = 'batch', weight_standard = args.weight_standard,appr_name =args.appr)\n",
    "    old_model = Siamese(encoder)\n",
    "    old_model.to(device) #automatically detects from model\n",
    "\n",
    "old_model.load_state_dict(dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Performance of the model train: 0.73272  test: 0.5262\n",
      "Task 0  acc train: 90.968000   acc test: 69.120000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1  acc train: 87.576000   acc test: 65.640000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2  acc train: 89.352000   acc test: 66.400000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3  acc train: 96.168000   acc test: 74.680000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task linear seperable performance train: 0.53856  test: 0.5251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "total_acc_train,  total_acc_test = total_performance(old_model, train_data_loaders_knn, test_data_loaders)#Not real performance just shows the linear seperability\n",
    "print(f'Total Performance of the model train: {total_acc_train}  test: {total_acc_test}')\n",
    "for task, loader in enumerate(train_data_loaders_knn):\n",
    "    acc, acc_test = train_clf(old_model, loader, test_data_loaders[task])\n",
    "    print(f\"Task {task}  acc train: {acc*100:2f}   acc test: {acc_test*100:2f}\")\n",
    "    print()\n",
    "\n",
    "task_seperability, task_seperability_test = train_task_seperation(old_model, train_data_loaders_knn, test_data_loaders)\n",
    "print(f'Task linear seperable performance train: {task_seperability}  test: {task_seperability_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedml_academic",
   "language": "python",
   "name": "fedml_academic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
