{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duygu/anaconda3/envs/fedml_academic/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"\")))\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "\n",
    "from dataloaders.dataloader_cifar10 import get_cifar10\n",
    "from dataloaders.dataloader_cifar100 import get_cifar100\n",
    "from utils.eval_metrics import linear_evaluation\n",
    "from models.linear_classifer import LinearClassifier\n",
    "from models.ssl import  SimSiam, Siamese, Encoder, Predictor\n",
    "\n",
    "import random\n",
    "from utils.lr_schedulers import LinearWarmupCosineAnnealingLR, SimSiamScheduler\n",
    "from utils.eval_metrics import Knn_Validation_cont\n",
    "from copy import deepcopy\n",
    "from loss import invariance_loss,CovarianceLoss,ErrorCovarianceLoss\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[0.1, 2.0]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = torchvision.transforms.functional.gaussian_blur(x,kernel_size=[3,3],sigma=sigma)#kernel size and sigma are open problems but right now seems ok!\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    normalization = 'batch'\n",
    "    weight_standard = False\n",
    "    same_lr = True\n",
    "    pretrain_batch_size = 512\n",
    "    pretrain_warmup_epochs = 10\n",
    "    pretrain_warmup_lr = 3e-3\n",
    "    pretrain_base_lr = 0.03\n",
    "    pretrain_momentum = 0.9\n",
    "    pretrain_weight_decay = 5e-4\n",
    "    min_lr = 0.00\n",
    "    lambdap = 1.0\n",
    "    appr = 'barlow_LRD'\n",
    "    knn_report_freq = 10\n",
    "    cuda_device = 1\n",
    "    num_workers = 8\n",
    "    contrastive_ratio = 0.001\n",
    "    dataset = 'cifar100'\n",
    "    class_split = [20,20,20,20,20]\n",
    "    epochs = [500,500,500,500,500]\n",
    "    cov_loss_weight = 1.0\n",
    "    sim_loss_weight = 250.0\n",
    "    info_loss = 'invariance'\n",
    "    lambda_norm = 1.0\n",
    "    subspace_rate = 0.99\n",
    "    lambda_param = 5e-3\n",
    "    bsize = 32\n",
    "    msize = 150\n",
    "    proj_hidden = 2048\n",
    "    proj_out = 2048 #infomax 64\n",
    "    pred_hidden = 512\n",
    "    pred_out = 2048\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"cifar10\":\n",
    "    get_dataloaders = get_cifar10\n",
    "    num_classes=10\n",
    "elif args.dataset == \"cifar100\":\n",
    "    get_dataloaders = get_cifar100\n",
    "    num_classes=100\n",
    "assert sum(args.class_split) == num_classes\n",
    "assert len(args.class_split) == len(args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "num_worker = args.num_workers\n",
    "#device\n",
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb init\n",
    "wandb.init(project=\"CSSL\",  entity=\"yavuz-team\",\n",
    "            mode=\"disabled\",\n",
    "            config=args,\n",
    "            name= str(args.dataset) + '-algo' + str(args.appr) + \"-e\" + str(args.epochs) + \"-b\" \n",
    "            + str(args.pretrain_batch_size) + \"-lr\" + str(args.pretrain_base_lr)+\"-CS\"+str(args.class_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    transform = T.Compose([\n",
    "            T.RandomResizedCrop(size=32, scale=(0.2, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)]), p=0.8),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomApply([GaussianBlur()], p=0.5), \n",
    "            T.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "    transform_prime = T.Compose([\n",
    "            T.RandomResizedCrop(size=32, scale=(0.2, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)]), p=0.8),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomApply([GaussianBlur()], p=0.5), \n",
    "            T.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataloaders..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Dataloaders\n",
    "print(\"Creating Dataloaders..\")\n",
    "#Class Based\n",
    "train_data_loaders, train_data_loaders_knn, test_data_loaders, _, train_data_loaders_linear, train_data_loaders_pure  = get_dataloaders(transform, transform_prime, \\\n",
    "                                    classes=args.class_split, valid_rate = 0.00, batch_size=args.pretrain_batch_size, seed = 0, num_worker= num_worker)\n",
    "_, train_data_loaders_knn_all, test_data_loaders_all, _, train_data_loaders_linear_all, train_data_loaders_pure_all = get_dataloaders(transform, transform_prime, \\\n",
    "                                        classes=[num_classes], valid_rate = 0.00, batch_size=args.pretrain_batch_size, seed = 0, num_worker= num_worker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    proj_hidden = args.proj_hidden\n",
    "    proj_out = args.proj_out\n",
    "    encoder = Encoder(hidden_dim=proj_hidden, output_dim=proj_out, normalization = args.normalization, weight_standard = args.weight_standard,appr_name =args.appr)\n",
    "    model0 = Siamese(encoder)\n",
    "    model0.to(device) #automatically detects from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.temporal_projector = nn.Sequential(\n",
    "            nn.Linear(args.proj_out, args.proj_hidden, bias=False),\n",
    "            nn.BatchNorm1d(args.proj_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.proj_hidden, args.proj_out),\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model here\n",
    "file_name = './checkpoints/checkpoint_cifar100-algocassle_barlow-e[500, 500, 500, 500, 500]-b256-lr0.25-CS[20, 20, 20, 20, 20]_task_0_same_lr_True_norm_batch_ws_False.pth.tar'\n",
    "dict = torch.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.load_state_dict(dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect activations\n",
    "def collect_activations(model,loader):\n",
    "    activations = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data_tuple in loader:\n",
    "            data, target = [t.to(device) for t in data_tuple]\n",
    "            # Forward prop of the model with single augmented batch\n",
    "            output = model(data)\n",
    "            activations.append(output.cpu().numpy())\n",
    "\n",
    "    activations = np.concatenate(activations)\n",
    "    return activations\n",
    "\n",
    "def get_eigenspectrum(activations, max_eigvals=2048):\n",
    "    \"\"\"\n",
    "    Given a (n x n) covariance matrix, compute the \n",
    "    eigenspectrum and the coefficient of decay by \n",
    "    fitting to the log-spectrum.\n",
    "    \"\"\"\n",
    "    act_shape = activations.shape\n",
    "    feats = activations.reshape(act_shape[0], -1)\n",
    "\n",
    "    # batchsize x featdim\n",
    "    bsz, feat_dim = feats.shape\n",
    "\n",
    "    centered_ft = feats - feats.mean(axis=0)\n",
    "    pca = PCA(n_components=min(max_eigvals, bsz, feat_dim), svd_solver='full')\n",
    "    pca.fit(centered_ft)\n",
    "    eigenspectrum = pca.explained_variance_ratio_\n",
    "    return eigenspectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = collect_activations(model0, train_data_loaders_knn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model here\n",
    "file_name = './checkpoints/checkpoint_cifar100-algocassle_barlow-e[500, 500, 500, 500, 500]-b256-lr0.25-CS[20, 20, 20, 20, 20]_task_4_same_lr_True_norm_batch_ws_False.pth.tar'\n",
    "#file_name = 'checkpoints/checkpoint_cifar100-algobasic_barlow-e[1000]-b256-lr0.3-CS[100]acc_69.65.pth.tar'\n",
    "#file_name = 'checkpoints/checkpoint_cifar100-algoLRD_cross_barlow-e[500, 500, 500, 500, 500]-b256-lr0.1-CS[20, 20, 20, 20, 20]acc_57.29.pth.tar'\n",
    "dict = torch.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.cuda_device) if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if 'infomax' in args.appr or 'barlow' in args.appr:\n",
    "    proj_hidden = args.proj_hidden\n",
    "    proj_out = args.proj_out\n",
    "    encoder = Encoder(hidden_dim=proj_hidden, output_dim=proj_out, normalization = args.normalization, weight_standard = args.weight_standard,appr_name =args.appr)\n",
    "    model1 = Siamese(encoder)\n",
    "    model1.to(device) #automatically detects from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.temporal_projector = nn.Sequential(\n",
    "            nn.Linear(args.proj_out, args.proj_hidden, bias=False),\n",
    "            nn.BatchNorm1d(args.proj_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.proj_hidden, args.proj_out),\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations1 = collect_activations(model1, train_data_loaders_knn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subspace(model, loader, rate=0.99,device = None, Q_prev = None, task=None):\n",
    "    model.eval()\n",
    "    outs = []\n",
    "    for x,y in loader:\n",
    "        x = x.to(device)\n",
    "        out = model(x).cpu().detach().numpy()\n",
    "        outs.append(out)\n",
    "\n",
    "    outs = np.concatenate(outs)\n",
    "    outs = outs.transpose()\n",
    "    outs = torch.tensor(outs)\n",
    "\n",
    "    if Q_prev == None:\n",
    "        projected = torch.zeros(1)\n",
    "    else:\n",
    "        Q_prev = Q_prev.to('cpu')\n",
    "        projected = Q_prev  @ Q_prev.T @ outs \n",
    "\n",
    "    remaining = outs - projected\n",
    "    U, S, V = torch.svd(remaining)\n",
    "    for i in range(len(S)):\n",
    "        total = torch.norm(outs)**2 \n",
    "        hand =  torch.norm(projected)**2 + torch.norm(S[0:i+1])**2\n",
    "        \n",
    "        if hand / total > rate:\n",
    "            break\n",
    "\n",
    "    print(U[:,0:i+1].shape)\n",
    "\n",
    "    if Q_prev == None:\n",
    "        Q_prev = U[:,0:i+1]\n",
    "    else:\n",
    "        Q_prev = torch.cat((Q_prev, U[:,0:i+1]),dim=1)\n",
    "        Q_prev, _ = torch.linalg.qr(Q_prev, mode=\"reduced\")\n",
    "    print(Q_prev.shape)\n",
    "    return Q_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 406])\n",
      "torch.Size([512, 406])\n"
     ]
    }
   ],
   "source": [
    "Q = extract_subspace(model1,train_data_loaders_knn[0],device=args.cuda_device,rate=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_projected = torch.tensor(activations) @ Q @ Q.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9651)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(activations_projected)/torch.norm(torch.tensor(activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedml_academic",
   "language": "python",
   "name": "fedml_academic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
